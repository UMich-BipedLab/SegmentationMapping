#!/usr/bin/python


# source: https://github.com/UMich-BipedLab/segmentation_projection
# maintainer: Ray Zhang    rzh@umich.edu


# ros
import rospy
import ros_numpy
import message_filters
from sensor_msgs.msg import Image, PointCloud, PointCloud2, ChannelFloat32
from geometry_msgs.msg import Point32  
from cv_bridge import CvBridge, CvBridgeError

# our projection library
from projection import LidarSeg
from NeuralNetConfigs import NeuralNetConfigs
# map label to color
from label2color import label_to_color, background
# our distortion lib
from distort import DistortMap
# load velodyne file
from project_vel_to_cam import load_vel_hits
# visualize pcl
from helper import publish_pcl_pc2_label

import cv2, time
import numpy as np
from scipy.ndimage import rotate
# debug
import pdb

class SegmentationProjectionNode:
    def __init__(self):
        # buffer 
        self.img_list = []
        self.pc_list  = []
        
        rospy.init_node('segmenation_projection_node', anonymous=True)
        rospy.sleep(0.5)

        try:
            is_train_input_tensor = rospy.get_param("~network_is_train_input_tensor")
        except KeyError:
            is_train_input_tensor = None
        try:
            distribution_tensor = rospy.get_param("~network_distribution_output_tensor")
        except KeyError:
            distribution_tensor = None
        
        # the segmentation object
        self.network_config = NeuralNetConfigs(rospy.get_param("~neural_net_graph"),\
                                               rospy.get_param("~num_classes"),\
                                               rospy.get_param("~network_image_input_tensor"),\
                                               is_train_input_tensor, \
                                               rospy.get_param("~neural_net_input_width"),\
                                               rospy.get_param("~neural_net_input_height"), \
                                               rospy.get_param("~network_label_output_tensor"),\
                                               distribution_tensor)
                                               
        self.lidar_seg = LidarSeg(self.network_config)

        # labeled pointcloud publisher
        label_pc_topic = rospy.get_param('~labeled_pointcloud')
        self.labeled_pointcloud_publisher = rospy.Publisher(label_pc_topic , PointCloud, queue_size=40)

        # lidar subscription
        lidar_topic = rospy.get_param('~lidar')
        lidar_sub   = message_filters.Subscriber(lidar_topic, PointCloud2)
        # for nclt only: pointcloud comes from synced files
        self.vel_path = rospy.get_param('~velodyne_synced_path')

        # multiple camera subscription
        camera_num  = rospy.get_param('~camera_num')
        image_topic_list = []
        sub_list   = []#[lidar_sub]
        
        # cv_bridge
        self.bridge = CvBridge()
        self.net_input_height = rospy.get_param("~neural_net_input_height")
        self.net_input_width  = rospy.get_param("~neural_net_input_width")


        # adding camera matrixes for each camera, and lidar_seg instance for each camera
        for i in range(camera_num):
            print("adding camera "+str(i))
            image_topic_list.append( rospy.get_param('~image_'+str(i)) )
            cam2lidar_file = rospy.get_param('~cam2lidar_file_'+str(i))
            intrinsic_file = rospy.get_param('~cam_intrinsic_'+str(i))
            distortion_file= rospy.get_param('~cam_distortion_'+str(i))
            T_cam2lidar    = np.load(cam2lidar_file)
            intrinsic_mat  = np.load(intrinsic_file)
            distort        = DistortMap(distortion_file)
            self.lidar_seg.add_cam(intrinsic_mat, T_cam2lidar, distort)
            sub_list.append(message_filters.Subscriber(image_topic_list[i], Image))
        
        # construct message filter
        print("construct ms filter "+str(len(sub_list)))
        ts = message_filters.ApproximateTimeSynchronizer(sub_list, 30, 0.06)
        ts.registerCallback(self.callback)
 

    def pc2_msg_to_lidar(self, original_pc):
        points = ros_numpy.numpify(original_pc)
        num_points = points.shape[0]
        lidar = np.ones((4, num_points), dtype=np.float32)
        for ind in range(num_points):
            p = points[ind]
            lidar[0, ind] = p[0]
            lidar[1, ind] = p[1]
            lidar[2, ind] = p[2]
        return lidar
        
        
    def publish_pointcloud_msg(self, lidar_header, lidar, labels, class_distribution, original_rgb):
        #declaring pointcloud
        to_publish = PointCloud()
        to_publish.header = lidar_header
        to_publish.header.frame_id = "body" # for nclt only
        
        # filling labels
        label_channel = ChannelFloat32()
        label_channel.name   = "labels"
        label_channel.values = labels
        r_channel = ChannelFloat32()
        r_channel.name = "r"
        r_channel.values = []
        g_channel = ChannelFloat32()
        g_channel.name = "g"
        g_channel.values = []
        b_channel = ChannelFloat32()
        b_channel.name = "b"
        b_channel.values = []
        r_original_channel = ChannelFloat32()
        r_original_channel.name = "r_original"
        r_original_channel.values = []
        g_original_channel = ChannelFloat32()
        g_original_channel.name = "g_original"
        g_original_channel.values = []
        b_original_channel = ChannelFloat32()
        b_original_channel.name = "b_original"
        b_original_channel.values = []

        if self.network_config.distribution_output_tensor is not None:
            distribution_channel_list = []
            for c in range(self.network_config.num_classes):
                dist_c = ChannelFloat32()
                dist_c.name = "p_class_"+str(c)
                dist_c.values = []
                distribution_channel_list.append(dist_c)
            
        for i in range(len(labels)):
            if labels[i] in label_to_color:
                color = label_to_color[labels[i]]
            else:
                color = label_to_color[background] # background
            r_channel.values.append(color[0])
            g_channel.values.append(color[1])
            b_channel.values.append(color[2])
            # use this instead if you want publish original rgb
	    r_original_channel.values.append(original_rgb[i][0])
	    g_original_channel.values.append(original_rgb[i][1])
            b_original_channel.values.append(original_rgb[i][2])
            if self.network_config.distribution_output_tensor is not None:
                assert(np.argmax(class_distribution[i]) == labels[i])
                for c in range(self.network_config.num_classes):
                    distribution_channel_list[c].values.append(class_distribution[i][c])
            
        to_publish.channels = [label_channel, r_channel, g_channel, b_channel, r_original_channel, g_original_channel, b_original_channel]
        if self.network_config.distribution_output_tensor is not None:
            to_publish.channels.extend(distribution_channel_list)
        
        #filling points
        to_publish.points = []
        for i in range(len(lidar)):
            p = Point32()
            p.x = lidar[i][0]
            p.y = lidar[i][1]
            p.z = lidar[i][2]
            to_publish.points.append(p)
            
        #publish
        print ("publishing pointcloud with labels, # of points is "+str(len(lidar)))
        self.labeled_pointcloud_publisher.publish(to_publish)



    def callback(self,* sub_list):
        start = time.time()
        img_msg_list = sub_list#sub_list[1:]
        #lidar_msg    = sub_list[0]
        #lidar = self.pc2_msg_to_lidar(lidar_msg)

        # note: nclt velodyne are synced files
        seq = str(int(round(float(int(img_msg_list[0].header.stamp.to_nsec()) )/  1000, 0  )))
        #if float(int(img_msg_list[0].header.stamp.to_nsec()) )/  1000 < 1335704344924045:
        #    print ("ignoring " + seq)
        #    return
        try:
            lidar = load_vel_hits(self.vel_path + seq +".bin")
        except IOError:
            print("velodyne file does not exist: " + self.vel_path + seq +".bin")
            return
        if (lidar.shape[1]< 5000):
            print("lidar points too few: # of points is "+str(lidar.shape[1])+" at time "+str(lidar_msg.header.stamp.to_sec()))
            return

        #print("callback at lidar time "+str(lidar_msg.header.stamp.to_sec()))
        print("camera time "+str(img_msg_list[0].header.stamp.to_sec())  + ", # of lidar points is " + str(lidar.shape[1]))

        '''
        if lidar.shape[1] == 51311:
            pdb.set_trace()
        else:
            return
        '''

        # result container for successfully projected points
        # and corresponding labels
        projected_lidar = []
        labeled_points  = []
        original_rgb = []
        class_distribution = []

	for i in range(len(img_msg_list)):
            original_img = self.bridge.imgmsg_to_cv2(img_msg_list[i] , desired_encoding="bgr8")
            original_image = rotate(original_img, 270)
            #if self.net_input_width > original_image.shape[1] or \
            #   self.net_input_height > original_image.shape[0]:
            #    original_image = cv2.copyMakeBorder(original_image,0,0,
            #                                  max(0, self.net_input_height - original_image.shape[0]),
            #                                  max(0, self.net_input_width-original_image.shape[1]),
            #                                  cv2.BORDER_CONSTANT,value=(0,0,0))
            cv_image = original_image[500:1100, -1200:]
            cv_image = cv2.resize(cv_image, \
                                  dsize=(self.network_config.input_width, self.network_config.input_height),\
                                  interpolation=cv2.INTER_CUBIC)
            #cv_image = original_image[:self.net_input_height, :self.net_input_width, :]
            #cv2.imwrite("original.png", cv_image)
            #cv2.imshow("original",to_show)
            #cv2.waitKey(0)
            
            labeled_points_i, projected_lidar_i, class_distribution_i, original_i = self.lidar_seg.project_lidar_to_seg(lidar,
                                                                                                                        cv_image,
                                                                                                                        i,
                                                                                                                        original_img)

            labeled_points  = labeled_points  + labeled_points_i
            projected_lidar = projected_lidar + projected_lidar_i
            class_distribution = class_distribution + class_distribution_i
            original_rgb = original_rgb + original_i

        # for debugging
        #publish_pcl_pc2_label(projected_lidar, labeled_points )
        
        self.publish_pointcloud_msg(img_msg_list[0].header, projected_lidar, labeled_points, class_distribution, original_rgb)
        print("time cost: " + str(time.time() - start) )

    def main(self):
        print("spin...")
        rospy.spin()
    


if __name__ == "__main__":

    node = SegmentationProjectionNode()
    node.main()


