#!/usr/bin/python



# ros
import rospy
import ros_numpy
import message_filters
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from std_msgs.msg import Float32MultiArray, MultiArrayLayout, MultiArrayDimension
from SegmentationMapping.msg import ImageLabelDistribution

# map label to color
from label2color import label_to_color, background
from NeuralNetConfigs import NeuralNetConfigs
# visualize pcl
#from helper import publish_pcl_pc2_label

import cv2, time
import numpy as np
from threading import Lock
from scipy.ndimage import rotate, zoom

import sys, os
if sys.version_info[0] < 3:
    import Queue as queue
else:
    import queue

import tensorflow as tf
    
# debug
import pdb



class SegmentationNode:
    def __init__(self):
        rospy.init_node('segmentation_node', anonymous=True)
        rospy.sleep(0.5)
        
        
        self.network_config = NeuralNetConfigs(rospy.get_param("~neural_net_graph"),\
                                               rospy.get_param("~num_classes"),\
                                               rospy.get_param("~network_image_input_tensor"),\
                                               "", \
                                               rospy.get_param("~neural_net_input_width"),\
                                               rospy.get_param("~neural_net_input_height"), \
                                               rospy.get_param("~network_label_output_tensor"),\
                                               rospy.get_param("~network_distribution_output_tensor"))
        print(self.network_config)
        self.tf_init()
        
        self.labeled_img_pub = rospy.Publisher("/labeled_image",
                                               Image, queue_size=10)
        self.distribution_pub = rospy.Publisher('/distribution_image',
                                               ImageLabelDistribution, queue_size=10)
        
        self.input_rgb_img_ = message_filters.Subscriber('/camera/color/image_raw',
                                                        Image,  queue_size=20)
        self.input_depth_img_ = message_filters.Subscriber('/camera/aligned_depth_to_color/image_raw', Image, queue_size=20)
        ts = message_filters.ApproximateTimeSynchronizer([self.input_rgb_img_, self.input_depth_img_], 20, 0.06)
        ts.registerCallback(self.callback)

        
        #self.skip_img_freq = rospy.get_param('~skip_input_img_freq')
        self.bridge = CvBridge()
        


        
    def callback(self, img_msg, depth_msg):
        print("New callback")
        original_img = self.bridge.imgmsg_to_cv2(img_msg , desired_encoding="rgb8")
        original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
        labeled_img, distribution = self.infer(original_img)
        self.publish_label_and_distribution(labeled_img, distribution, img_msg.header)
        
    def tf_init(self):

        with tf.gfile.GFile(self.network_config.path, 'rb') as f:
            self.graph_def = tf.GraphDef()
            self.graph_def.ParseFromString(f.read())


        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        self.sess = tf.Session(config=config)
        self.y, = tf.import_graph_def(self.graph_def, return_elements=[self.network_config.label_output_tensor], name='')
        self.G = tf.get_default_graph() 
        self.x = self.G.get_tensor_by_name(self.network_config.image_input_tensor)
        
        self.dist = self.G.get_tensor_by_name(self.network_config.distribution_output_tensor)
        tf.global_variables_initializer().run(session=self.sess)
        print("Tf init finish")


    def publish_label_and_distribution(self, labeled_img, distribution, header):
        
        label_msg = self.bridge.cv2_to_imgmsg(labeled_img, encoding="mono8")
        label_msg.header = header

        distribution_msg = ImageLabelDistribution()
        m_arr = Float32MultiArray()
        m_arr.layout.data_offset = 0
        m_arr.layout.dim = [MultiArrayDimension() for _ in range(3)]
        m_arr.layout.dim[0].label = "h"
        m_arr.layout.dim[0].size  = labeled_img.shape[0]
        m_arr.layout.dim[0].stride = self.network_config.num_classes * labeled_img.size
        m_arr.layout.dim[1].label = "w"
        m_arr.layout.dim[1].size  = labeled_img.shape[1]
        m_arr.layout.dim[1].stride = self.network_config.num_classes * labeled_img.shape[1]
        m_arr.layout.dim[2].label = "c"
        m_arr.layout.dim[2].size = self.network_config.num_classes
        m_arr.layout.dim[2].stride = self.network_config.num_classes
        m_arr.data = distribution.flatten().tolist()

        print(len(m_arr.data) * 4)
        
        distribution_msg.header = header
        distribution_msg.distribution = m_arr

        self.labeled_img_pub.publish(label_msg)
        self.distribution_pub.publish(distribution_msg)
        

    def infer(self, rgb_img):

        num_class = self.network_config.num_classes

        #if rgb_img.shape[0] != self.network_config.input_height or \
        #   rgb_img.shape[1] != self.network_config.input_width:
        #    rgb = cv2.resize(rgb_img, \
        #                     dsize=(self.network_config.input_width, self.network_config.input_height),\
        #                     interpolation=cv2.INTER_CUBIC)
        #else:
        #    rgb = rgb_img
        
        rgb = rgb_img 
        rgb = np.expand_dims(rgb, axis=0)
        
        label_out, dist_out = self.sess.run([self.y, self.dist], feed_dict={self.x: rgb})

        dist_out = dist_out[0, :, :, :]
        label_out = label_out[0, :, : ].astype(np.uint8)
        print("finish infer "+str(label_out.shape)+", "+ str(dist_out.shape)  )

        '''
        dist_exp = np.exp(dist_out)
        dist_class = dist_exp
        #dist_class = zoom(dist_exp, (1.2, 640.0/800 , 1)).astype(np.float32)
        dist_sum = np.sum(dist_class, axis=2, keepdims=1)

        dist_class = dist_class / dist_sum
        assert(np.sum(dist_class[1,1,:]) > 0.99 and np.sum(dist_class[1,1,:]) < 1.01)
        background_sum = np.sum(dist_class[:, :, num_class:], axis=2)
        dist_class = dist_class[:, :, :num_class]
        dist_class[:,:,0] += background_sum
        assert(np.sum(dist_class[1,1,:]) > 0.99 and np.sum(dist_class[1,1,:]) < 1.01)
        label_img = np.argmax(dist_class, axis=2).astype(np.uint8)
        print (label_img.dtype)
        #label_img = cv2.resize(label_img, \
        #                 dsize=(rgb_img.shape[1], rgb_img.shape[0]),\
        #                       interpolation=cv2.INTER_NEAREST).astype(np.uint8)

        '''
        print(label_out.shape, dist_out.shape)        
        return label_out, dist_out

    def spin(self):
        rospy.spin()

if __name__ == "__main__":
    node = SegmentationNode()
    node.spin()
